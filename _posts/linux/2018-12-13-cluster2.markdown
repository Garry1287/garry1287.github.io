---
layout: post
title:  "cluster2"
date:   2018-12-13 00:18:22 +0300
categories: linux
tags: linux
---

# cluster2
[http://itimage.ru/?p=84](http://itimage.ru/?p=84)

если с линуксом на короткой ноге, то ESX отлично подойдет.
причем iESX вроде как бесплатный


[https://habr.com/ru/company/ispsystem/blog/313066/](https://habr.com/ru/company/ispsystem/blog/313066/)
[https://www.thegeekdiary.com/beginner-guide-to-rhel-7-high-availability-cluster-architectural-overview/](https://www.thegeekdiary.com/beginner-guide-to-rhel-7-high-availability-cluster-architectural-overview/)


[https://www.tecmint.com/rhev-clustering-and-rhel-hypervisors-installation/](https://www.tecmint.com/rhev-clustering-and-rhel-hypervisors-installation/)
[https://access.redhat.com/documentation/ru-ru/red_hat_enterprise_linux/6/html/high_availability_add-on_overview/s1-virt-guestcluster](https://access.redhat.com/documentation/ru-ru/red_hat_enterprise_linux/6/html/high_availability_add-on_overview/s1-virt-guestcluster)



ну вы хотите квм видимо
овирт более ручной, проксмокс более веб интерфейсный, что то я не помню там онлайн миграции при падении квм сказать честно . 



Open Nebula vs oVirt vs Proxmox. Кто что посоветует для трех распределённых территориально дата центров с первыми сотнями хостов и первыми тысячами виртуалок?

ЗЫ: Open Stack не мой случай. КМК Это для провайдеров облаков IaaS - барыжить виртуальными ЦОДами.


[https://habr.com/ru/post/335530/](https://habr.com/ru/post/335530/)
[https://habr.com/ru/company/stss/blog/279589/](https://habr.com/ru/company/stss/blog/279589/)


opennebula


Перешел с проксмокса на овирт из-за роста нагрузки. Абсолютно адекватное решение для частного кластера, пока не дорос до opennebula/openstack. А с учетом гейтвея для VDI вообще единственное.


Сколько планируется виртуальных машин? Если нужны контейнеры, то выбор невелик. Без внешнего стораджа и с контейнерами - проксмокс. Тем более забикс на него раскидать без проблем.

Особо контейнеры без нужды, единичные в докере на виртуальном хосте крутятся.

С одной стороны 50 - много для прокса, ручное управление надоедает. С другой стороны без общей хранилки ничего сделать нельзя.

Цеф не советую, ни сети, ни дисков, да еще при большой нагрузке или выбивании диска он может выжирать бесконтрольно память, что скажется на виртуалках.

А зачем аж 5 серверов для 50 виртуалок, они слабые или виртуалки жирные? Больше серверов - больше мороки.

[https://www.linux.org.ru/forum/admin/13617546](https://www.linux.org.ru/forum/admin/13617546)



[https://habr.com/ru/post/278877/](https://habr.com/ru/post/278877/)
[https://bobcares.com/blog/how-we-configured-container-as-a-service-in-ovirt/](https://bobcares.com/blog/how-we-configured-container-as-a-service-in-ovirt/)


Ovirt
[https://blog.it-kb.ru/2016/09/10/install-ovirt-4-0-part-1-create-two-node-hosted-engine-cluster-with-shared-fc-san-storage/](https://blog.it-kb.ru/2016/09/10/install-ovirt-4-0-part-1-create-two-node-hosted-engine-cluster-with-shared-fc-san-storage/)
[https://itsecforu.ru/2019/01/11/%D0%BA%D0%B0%D0%BA-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%B8%D1%82%D1%8C-ovirt-%D0%BD%D0%B0-centos-7/](https://itsecforu.ru/2019/01/11/%D0%BA%D0%B0%D0%BA-%D1%83%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%B8%D1%82%D1%8C-ovirt-%D0%BD%D0%B0-centos-7/)



У меня уже с год бегают шесть узлов, в связке: webvirt + libvirt + zfs + kvm


есть веб-морды к kvm, Proxmox+ZFS+KVM
